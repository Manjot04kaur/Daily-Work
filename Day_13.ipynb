{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKcrNU3o8rsaIk9y5pMPb1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manjot04kaur/Daily-Work/blob/main/Day_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Day 13**\n",
        "\n",
        "**Date 21 June 2024**\n",
        "\n",
        "**Daily Report**\n",
        "\n",
        "Today's session was based on Method of Deep Learing - Artificial Neural Natwork\n",
        "\n",
        "---\n",
        "\n",
        "**Today's topic**\n",
        "\n",
        "---\n",
        "\n",
        "**1. Artificial Neural Network**\n",
        "\n",
        "The term \"Artificial neural network\" refers to a biologically inspired sub-field of artificial intelligence modeled after the brain. An Artificial neural network is usually a computational network based on biological neural networks that construct the structure of the human brain. Similar to a human brain has neurons interconnected to each other, artificial neural networks also have neurons that are linked to each other in various layers of the networks.\n",
        "\n",
        "**2. Activation Function**\n",
        "\n",
        "Activation functions are an extremely important feature of the artificial neural networks.\n",
        "They basically decide whether a neuron should be activated or not. Whether the\n",
        "information that the neuron is receiving is relevant for the given information or should it\n",
        "be ignored.\n",
        " * Linear Activation Function\n",
        " * Non Linear Activation Function\n",
        "\n",
        "**3. Threshold Function**\n",
        "\n",
        "**4. Sigmoid Function**\n",
        "The Sigmoid Function curve looks like a S-shape\n",
        "This function reduces extreme values or outliers in data without removing them.\n",
        "It converts independent variables of near infinite range into simple probabilities\n",
        "between 0 and 1, and most of its output will be very close to 0 or 1.\n",
        "\n",
        "\n",
        "**5. Rectifier (Relu) Function**\n",
        "ReLU is the most widely used activation function while designing networks today.\n",
        "First things first, the ReLU function is non linear, which means it can\n",
        "backpropagate the errors and have multiple layers of neurons being activated by the\n",
        "ReLU function.\n",
        "\n",
        "\n",
        "**6. Leaky Relu Function**\n",
        "Leaky ReLU function is nothing but an improved version of the ReLU function. As\n",
        "for the ReLU function, the gradient is 0 for ``` x<0 ``` which made the neurons die for activations in\n",
        "that region. Leaky ReLU is defined to address this problem. Instead of defining the Relu\n",
        "function as 0 for x less than 0, it can define as a small linear function of x\n",
        "\n",
        "\n",
        "**7. Hyperbolic Tangent Function**\n",
        "Pronounced “tanch,” tanh is a hyperbolic trigonometric function\n",
        "The tangent represents a ratio between the opposite and adjacent sides of a right triangle,\n",
        "tanh represents the ratio of the hyperbolic sine to the hyperbolic cosine: tanh(x) = sinh(x) /\n",
        "cosh(x)\n",
        "Unlike the Sigmoid function, the normalized range of tanh is –1 to 1 The advantage of tanh is\n",
        "that it can deal more easily with negative numbers.\n",
        "\n",
        "\n",
        "**8. Softmax Function**\n",
        "Softmax function calculates the probabilities distribution of the event over ‘n’ different events. In general way of\n",
        "saying, this function will calculate the probabilities of each target class over all possible target classes. Later the\n",
        "calculated probabilities will be helpful for determining the target class for the given inputs.\n",
        "\n",
        "\n",
        "**9. Back Propogation in Deep Learning**\n",
        "Back-propagation is the essence of neural net training. It is the method of\n",
        "fine-tuning the weights of a neural net based on the error rate obtained in the\n",
        "previous epoch (i.e., iteration). Proper tuning of the weights allows you to reduce\n",
        "error rates and to make the model reliable by increasing its generalization.\n",
        "\n",
        "This method helps to\n",
        "calculate the gradient of a loss function with respects to all the weights in the network\n",
        "\n",
        "\n",
        "**10. Interpretation of ANN in Python**\n",
        "\n",
        "  Libraries are used:-\n",
        "\n",
        "  * Pandas\n",
        "  * scikit learn\n",
        "  * Numpy\n",
        "  * Tenser Flow\n",
        "  * keras\n"
      ],
      "metadata": {
        "id": "mGDijqcEJwsz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoFVbDcDJnua"
      },
      "outputs": [],
      "source": []
    }
  ]
}